"use strict";(globalThis.webpackChunkrock_docs=globalThis.webpackChunkrock_docs||[]).push([[2054],{3134(e,n,i){i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>t});const s=JSON.parse('{"id":"References/model-service","title":"Model Service\uff08Experimental\uff09","description":"The Model Service provided by ROCK is responsible for handling AI model call communications, serving as a communication bridge between agents and training frameworks (such as Roll) or actual LLM inference services.","source":"@site/versioned_docs/version-1.0.x/References/model-service.md","sourceDirName":"References","slug":"/References/model-service","permalink":"/ROCK/docs/1.0.x/References/model-service","draft":false,"unlisted":false,"editUrl":"https://github.com/alibaba/ROCK/tree/master/docs/versioned_docs/version-1.0.x/References/model-service.md","tags":[],"version":"1.0.x","lastUpdatedAt":1770114841000,"sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"API Reference","permalink":"/ROCK/docs/1.0.x/References/api"},"next":{"title":"Sandbox Agent\uff08Experimental\uff09","permalink":"/ROCK/docs/1.0.x/References/sandbox-agent"}}');var r=i(4848),o=i(8453);const l={sidebar_position:2},c="Model Service\uff08Experimental\uff09",d={},t=[{value:"Architecture Overview",id:"architecture-overview",level:2},{value:"CLI Commands",id:"cli-commands",level:2},{value:"start command",id:"start-command",level:3},{value:"watch-agent command",id:"watch-agent-command",level:3},{value:"stop command",id:"stop-command",level:3},{value:"anti-call-llm command",id:"anti-call-llm-command",level:3},{value:"File Communication Protocol",id:"file-communication-protocol",level:2},{value:"Request Format",id:"request-format",level:3},{value:"Response Format",id:"response-format",level:3},{value:"Session End Marker",id:"session-end-marker",level:3},{value:"Sandbox Integration",id:"sandbox-integration",level:2},{value:"ModelServiceConfig",id:"modelserviceconfig",level:3},{value:"ModelService Class",id:"modelservice-class",level:3},{value:"Workflow",id:"workflow",level:2},{value:"Configuration Options",id:"configuration-options",level:2},{value:"Service Configuration",id:"service-configuration",level:3},{value:"Log Configuration",id:"log-configuration",level:3},{value:"Polling Configuration",id:"polling-configuration",level:3},{value:"Marker Configuration",id:"marker-configuration",level:3}];function a(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"model-serviceexperimental",children:"Model Service\uff08Experimental\uff09"})}),"\n",(0,r.jsx)(n.p,{children:"The Model Service provided by ROCK is responsible for handling AI model call communications, serving as a communication bridge between agents and training frameworks (such as Roll) or actual LLM inference services."}),"\n",(0,r.jsx)(n.h2,{id:"architecture-overview",children:"Architecture Overview"}),"\n",(0,r.jsx)(n.p,{children:"The model service uses the file system as a communication medium, implementing a request-response mechanism between agents and models. When an agent needs to call a model, the request is first written to a log file, then processed by the listening component. When the model generates a response, the result is written back to the log file and read by the waiting agent."}),"\n",(0,r.jsx)(n.h2,{id:"cli-commands",children:"CLI Commands"}),"\n",(0,r.jsxs)(n.p,{children:["To use the model service via CLI, ROCK provides a set of CLI commands that can be accessed via ",(0,r.jsx)(n.code,{children:"rock model-service"})," after installing ROCK in the sandbox:"]}),"\n",(0,r.jsx)(n.h3,{id:"start-command",children:"start command"}),"\n",(0,r.jsx)(n.p,{children:"Start the model service process"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"rock model-service start --type [local|proxy]\n"})}),"\n",(0,r.jsx)(n.p,{children:"Parameters:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"--type"}),": Model service type, optional ",(0,r.jsx)(n.code,{children:"local"})," or ",(0,r.jsx)(n.code,{children:"proxy"}),", defaults to ",(0,r.jsx)(n.code,{children:"local"})]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"watch-agent-command",children:"watch-agent command"}),"\n",(0,r.jsx)(n.p,{children:"Monitor the agent process and send a SESSION_END message when the process exits"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"rock model-service watch-agent --pid <process_id>\n"})}),"\n",(0,r.jsx)(n.p,{children:"Parameters:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"--pid"}),": The ID of the agent process to monitor"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"stop-command",children:"stop command"}),"\n",(0,r.jsx)(n.p,{children:"Stop the model service"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"rock model-service stop\n"})}),"\n",(0,r.jsx)(n.h3,{id:"anti-call-llm-command",children:"anti-call-llm command"}),"\n",(0,r.jsx)(n.p,{children:"Anti-call the LLM interface"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"rock model-service anti-call-llm --index <index> [--response <response>]\n"})}),"\n",(0,r.jsx)(n.p,{children:"Parameters:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"--index"}),": Index of the previous LLM call, starting from 0"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"--response"}),": Response from the previous LLM call (optional)"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"file-communication-protocol",children:"File Communication Protocol"}),"\n",(0,r.jsx)(n.p,{children:"The model service uses files for inter-process communication, defining specific marker formats to distinguish requests and responses:"}),"\n",(0,r.jsx)(n.h3,{id:"request-format",children:"Request Format"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"LLM_REQUEST_START{JSON request data}LLM_REQUEST_END{metadata JSON}\n"})}),"\n",(0,r.jsx)(n.h3,{id:"response-format",children:"Response Format"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"LLM_RESPONSE_START{JSON response data}LLM_RESPONSE_END{metadata JSON}\n"})}),"\n",(0,r.jsx)(n.h3,{id:"session-end-marker",children:"Session End Marker"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"SESSION_END\n"})}),"\n",(0,r.jsx)(n.p,{children:"Metadata contains timestamp and index information to ensure message order and processing."}),"\n",(0,r.jsx)(n.h2,{id:"sandbox-integration",children:"Sandbox Integration"}),"\n",(0,r.jsx)(n.h3,{id:"modelserviceconfig",children:"ModelServiceConfig"}),"\n",(0,r.jsxs)(n.p,{children:["Located in ",(0,r.jsx)(n.code,{children:"rock/sdk/sandbox/model_service/base.py"}),", defines model service configuration in the sandbox:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Working directory"}),"\n",(0,r.jsx)(n.li,{children:"Python and model service installation commands"}),"\n",(0,r.jsx)(n.li,{children:"Session environment variables"}),"\n",(0,r.jsx)(n.li,{children:"Various command templates"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"modelservice-class",children:"ModelService Class"}),"\n",(0,r.jsx)(n.p,{children:"Handles the lifecycle of model services within the sandbox:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"install()"}),": Install model service dependencies in the sandbox"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"start()"}),": Start the model service"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"stop()"}),": Stop the model service"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"watch_agent()"}),": Monitor the agent process"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"anti_call_llm()"}),": Perform anti-call LLM operations"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"workflow",children:"Workflow"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Agent initiates a model call request"}),"\n",(0,r.jsx)(n.li,{children:"Request is formatted and written to a log file"}),"\n",(0,r.jsx)(n.li,{children:"Model service listens to the log file and captures new requests"}),"\n",(0,r.jsx)(n.li,{children:"Runtime (Roll) processes the request and generates a response"}),"\n",(0,r.jsx)(n.li,{children:"Response is written to the log file"}),"\n",(0,r.jsx)(n.li,{children:"Model service returns the response to the agent"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"configuration-options",children:"Configuration Options"}),"\n",(0,r.jsx)(n.h3,{id:"service-configuration",children:"Service Configuration"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"SERVICE_HOST"}),': Service host address, defaults to "0.0.0.0"']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"SERVICE_PORT"}),": Service port, defaults to 8080"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"log-configuration",children:"Log Configuration"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"LOG_FILE"}),": Log file path used for communication, containing request and response data"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"polling-configuration",children:"Polling Configuration"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"POLLING_INTERVAL_SECONDS"}),": Polling interval, defaults to 0.1 seconds"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"REQUEST_TIMEOUT"}),": Request timeout, defaults to unlimited"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"marker-configuration",children:"Marker Configuration"}),"\n",(0,r.jsx)(n.p,{children:"Defines markers used to distinguish different types of messages in the log file:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"REQUEST_START_MARKER"})," / ",(0,r.jsx)(n.code,{children:"REQUEST_END_MARKER"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"RESPONSE_START_MARKER"})," / ",(0,r.jsx)(n.code,{children:"RESPONSE_END_MARKER"})]}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"SESSION_END_MARKER"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(a,{...e})}):a(e)}},8453(e,n,i){i.d(n,{R:()=>l,x:()=>c});var s=i(6540);const r={},o=s.createContext(r);function l(e){const n=s.useContext(o);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);