# v1.2.0

## Release Date
February 3, 2026


---

## SDK

### New Features

#### Runtime Environment
**[Runtime Environment References Documentation](../References/Python%20SDK%20References/runtime-env.md)**

- **NEW**: Executable symlink support via `extra_symlink_dir` and `extra_symlink_executables` for exposing runtime executables to system paths

#### Model Service (Experimental)
**[Model Service References Documentation](../References/Python%20SDK%20References/model-service.md)**

Handles AI model call communications between agents and LLM inference services:
- Local mode: File-based IPC between Agent and Roll runtime, implementing request-response via file protocol
- Proxy mode: Request forwarding to external LLM services with routing and retry support

- SDK supports `anti_call_llm` for proxying Agent requests
- **NEW**: Complete CLI start command parameters (`--config-file`, `--host`, `--port`, `--proxy-base-url`, `--retryable-status-codes`, `--request-timeout`)
- **NEW**: Trajectory (traj) logging - records LLM request/response to JSONL files (`ROCK_MODEL_SERVICE_DATA_DIR`, `ROCK_MODEL_SERVICE_TRAJ_APPEND_MODE`)
- **NEW**: Server-side `ModelServiceConfig` configuration (`host`, `port`, `proxy_base_url`, `proxy_rules`, `retryable_status_codes`, `request_timeout`)

#### Agent Examples
**[Examples Directory](https://github.com/Modelized/ROCK/tree/master/examples/agents)**

Practical examples demonstrating ROCK Agent integration with various AI frameworks:

- **claude_code/**: Claude Code Agent integration example using Node.js runtime
  - Command: `claude -p ${prompt}`
  - Requires: `npm install -g @anthropic-ai/claude-code`
  - Configuration via `rock_agent_config.yaml`

- **iflow_cli/**: iFlow CLI Agent integration example using Node.js runtime
  - Command: `iflow -p ${prompt} --yolo`
  - Requires: `npm i -g @iflow-ai/iflow-cli@latest`

- **swe_agent/**: SWE Agent integration example
  - Demonstrates standard ROCK Agent setup pattern

- **iflow_cli/integration_with_model_service/**: Model Service integration examples
  - **local/**: Local mode example with custom LLM backend
    - Shows `anti_call_llm` usage and model service loop pattern
  - **proxy/**: Proxy mode example with iFlow CLI
    - Demonstrates `rock model-service start --type proxy --proxy-base-url` usage


## Admin
