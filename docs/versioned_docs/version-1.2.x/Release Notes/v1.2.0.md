# v1.2.0

## Release Date
February 3, 2026


---

## SDK

### New Features

#### Runtime Environment
**[Runtime Environment References Documentation](../References/Python%20SDK%20References/runtime-env.md)**

- **NEW**: Executable symlink support via `extra_symlink_dir` and `extra_symlink_executables` for exposing runtime executables to system paths

#### Model Service (Experimental)
**[Model Service References Documentation](../References/Python%20SDK%20References/model-service.md)**

Handles AI model call communications between agents and LLM inference services:
- Local mode: File-based IPC between Agent and Roll runtime, implementing request-response via file protocol
- Proxy mode: Request forwarding to external LLM services with routing and retry support

- SDK supports `anti_call_llm` for proxying Agent requests
- **NEW**: Complete CLI start command parameters (`--config-file`, `--host`, `--port`, `--proxy-base-url`, `--retryable-status-codes`, `--request-timeout`)
- **NEW**: Trajectory (traj) logging - records LLM request/response to JSONL files (`ROCK_MODEL_SERVICE_DATA_DIR`, `ROCK_MODEL_SERVICE_TRAJ_APPEND_MODE`)
- **NEW**: Server-side `ModelServiceConfig` configuration (`host`, `port`, `proxy_base_url`, `proxy_rules`, `retryable_status_codes`, `request_timeout`)

#### Agent Examples
**[Examples Directory](https://github.com/Modelized/ROCK/tree/master/examples/agents)**

Practical examples demonstrating ROCK Agent integration with various AI frameworks:

- **claude_code/**: Claude Code Agent integration example using Node.js runtime
  - Command: `claude -p ${prompt}`
  - Requires: `npm install -g @anthropic-ai/claude-code`
  - Configuration via `rock_agent_config.yaml`

- **iflow_cli/**: iFlow CLI Agent integration example using Node.js runtime
  - Command: `iflow -p ${prompt} --yolo`
  - Requires: `npm i -g @iflow-ai/iflow-cli@latest`

- **swe_agent/**: SWE Agent integration example
  - Demonstrates standard ROCK Agent setup pattern

- **iflow_cli/integration_with_model_service/**: Model Service integration examples
  - **local/**: Local mode example with custom LLM backend
    - Shows `anti_call_llm` usage and model service loop pattern
  - **proxy/**: Proxy mode example with iFlow CLI
    - Demonstrates `rock model-service start --type proxy --proxy-base-url` usage


## Admin

### New Features

#### Task Scheduler
A flexible task scheduling system for managing periodic maintenance tasks across Ray workers.

**Built-in Tasks:**
- **ImageCleanupTask**: Docker image cleanup using [docuum](https://github.com/stepchowfun/docuum) with configurable disk threshold

**Configuration Example:**
```yaml
scheduler:
  enabled: true
  worker_cache_ttl: 3600
  tasks:
    - task_class: "rock.admin.scheduler.tasks.image_cleanup_task.ImageCleanupTask"
      enabled: true
      interval_seconds: 3600
      params:
        threshold: "1T"
```

**Extensibility:**
Create custom tasks by extending `BaseTask` and implementing the `run_action(runtime: RemoteSandboxRuntime)` method.

#### Entrypoints

- **NEW**: Batch sandbox status query API (`POST /sandboxes/batch`)
  - Efficiently retrieve status information for multiple sandboxes in a single request
  - Accepts `BatchSandboxStatusRequest` with `sandbox_ids` list
  - Returns `BatchSandboxStatusResponse` containing status details for all requested sandboxes
  - Supports up to configurable maximum count (default from `batch_get_status_max_count`)

- **NEW**: Sandbox listing and filtering API (`GET /sandboxes`)
  - Query and filter sandboxes with flexible query parameters
  - Supports pagination via `page` and `page_size` parameters
  - Returns `SandboxListResponse` with items, total count, and `has_more` indicator
  - Enables filtering by sandbox attributes (e.g., deployment type, status, custom metadata)
  - Maximum page size configurable via `batch_get_status_max_count`

#### Sandbox

- Modify Sandbox log format: use iso 8601 format for timestamp, default time zone is Asia/Shanghai
- Enrich SandboxInfo: add create_time, start_time, stop_time for metrics
- Add Billing log when sandbox is closed

---

### Enhancements

#### Performance Optimizations
- Decouple the `get_status` API logic from Ray, reducing API latency from 1s+ to 100ms+; support dynamically toggling between the new and legacy logic.
